{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[line](#link_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.19.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn.datasets as sk_datasets\n",
    "iris = sk_datasets.load_iris()\n",
    "iris_x = iris.data\n",
    "iris_y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.64459602,  0.92767918, -1.32091378, -1.25725859, -0.74386837],\n",
       "        [ 1.66098845,  2.22206181, -2.86249859, -3.28323172, -1.62389676],\n",
       "        [ 0.27019475, -0.12572907,  1.1003977 , -0.6600737 ,  0.58334745],\n",
       "        [-0.77182836, -1.03692724,  1.34422289,  1.52452016,  0.76221055],\n",
       "        [-0.1407289 ,  0.32675611, -1.41296696,  0.4113583 , -0.75833145],\n",
       "        [-0.76656634, -0.35589955, -0.83132182,  1.68841011, -0.4153836 ]]),\n",
       " array([0, 0, 0, 1, 1, 1]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.datasets.samples_generator as sk_samples_generator\n",
    "# creat dataset\n",
    "x, y = sk_samples_generator.make_classification(n_samples=6, n_features=5, n_informative=2, n_redundant=3, n_classes=2, n_clusters_per_class=2, scale=1, random_state=20)\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## create the train and test datasets\n",
    "import sklearn.model_selection as sk_model_selection\n",
    "x_train, x_test, y_train, y_test = sk_model_selection.train_test_split(iris_x,iris_y,train_size=0.3, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base on mean and std: \n",
      "[[ 1.41421356 -1.33630621  1.37281295]\n",
      " [-0.70710678  1.06904497 -0.39223227]\n",
      " [-0.70710678  0.26726124 -0.98058068]]\n"
     ]
    }
   ],
   "source": [
    "## 基于mean和std的标准化\n",
    "import sklearn.preprocessing as sk_preprocessing\n",
    "x = [[1, -1, 2],[0, 2, -1],[0, 1, -2]]\n",
    "scaler = sk_preprocessing.StandardScaler().fit(x)\n",
    "new_x = scaler.transform(x)\n",
    "print('base on mean and std: ')\n",
    "print(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 1.        ],\n",
       "       [0.        , 1.        , 0.25      ],\n",
       "       [0.        , 0.66666667, 0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 基于在一定范围内的标准化\n",
    "scaler = sk_preprocessing.MinMaxScaler(feature_range=(0,1)).fit(x)\n",
    "new_x = scaler.transform(x)\n",
    "new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.40824829, -0.40824829,  0.81649658],\n",
       "        [ 0.        ,  0.89442719, -0.4472136 ],\n",
       "        [ 0.        ,  0.4472136 , -0.89442719]]),\n",
       " [[1, -1, 2], [0, 2, -1], [0, 1, -2]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 求范数\n",
    "new_x = sk_preprocessing.normalize(x, norm='l2')\n",
    "new_x,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "降维后的各主成分的方差值占总方差值的比例，各主成分的方差值，特征数\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.92461621, 0.05301557, 0.01718514]),\n",
       " array([4.22484077, 0.24224357, 0.07852391]),\n",
       " 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## PCA analysis\n",
    "import sklearn.decomposition as sk_decomposition\n",
    "##参数说明：\n",
    "#n_components：指定希望PCA降维后的特征维度数目(>1)， 指定主成分的方差和所占的最小比例阈值（0-1），'mle'用MLE算法根据特征的方差分布情况自己去选择一定数量的主成分特征来降维\n",
    "#whiten： 判断是否进行白化。白化：降维后的数据的每个特征进行归一化，让方差都为1\n",
    "#svd_solver：奇异值分解SVD的方法{‘auto’, ‘full’, ‘arpack’, ‘randomized’}\n",
    "pca = sk_decomposition.PCA(n_components='mle', whiten=False, svd_solver='auto')\n",
    "pca.fit(iris_x)\n",
    "reduced_x = pca.transform(iris_x)\n",
    "print(\"降维后的各主成分的方差值占总方差值的比例，各主成分的方差值，特征数\")\n",
    "pca.explained_variance_ratio_, pca.explained_variance_, pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA:\n",
      "LDA的数据中心点： [[5.006 3.418 1.464 0.244]\n",
      " [5.936 2.77  4.26  1.326]\n",
      " [6.588 2.974 5.552 2.026]]\n",
      "LDA做分类时的正确率: 0.9809523809523809\n",
      "LDA降维后特征空间的类中心:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.81926852,  0.03285975],\n",
       "       [ 1.5478732 ,  2.15471106],\n",
       "       [-2.18494056, -0.93024679],\n",
       "       [-2.85385002,  2.8060046 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## LDA preprocessing  线性评价分析\n",
    "import sklearn.discriminant_analysis as sk_discriminant_analysis\n",
    "# 参数说明：\n",
    "#n_components：指定希望PCA降维后的特征维度数目(>1)\n",
    "#svd_solver：奇异值分解SVD的方法{‘auto’, ‘full’, ‘arpack’, ‘randomized’}\n",
    "lda = sk_discriminant_analysis.LinearDiscriminantAnalysis(n_components=2)\n",
    "lda.fit(iris_x, iris_y)\n",
    "reduced_x = lda.transform(iris_x) # 降维后数据\n",
    "print(\"LDA:\")\n",
    "print(\"LDA的数据中心点：\"),lda.means_\n",
    "print(\"LDA做分类时的正确率:\"),lda.score(x_test,y_test)\n",
    "print(\"LDA降维后特征空间的类中心:\")\n",
    "lda.scalings_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# machine-learning  in sklearn<a id=\"link_first\"></a>\n",
    "\n",
    "1. model fit\n",
    "```\n",
    "model.fit(x_train, y_train)\n",
    "```\n",
    "2. model predict\n",
    "```\n",
    "model.predict(x_test)\n",
    "```\n",
    "3. get the parameters of the model\n",
    "```\n",
    "mdoel.get_params()\n",
    "```\n",
    "4. the score of the model, evalution standard:regression issues-$R^2$, classification issues-accuracy \n",
    "```\n",
    "model.score(data_X, data_Y)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "截距: -0.3799538667451592\n",
      "系数: [-0.02744885  0.01662843  0.17780211  0.65838886]\n",
      "线性回归模型评价: 0.913431360637617\n"
     ]
    }
   ],
   "source": [
    "## linear regression\n",
    "import sklearn.linear_model as sk_linear\n",
    "## 参数说明：\n",
    "#fit_intercept：是否计算截距。False-模型没有截距\n",
    "#normalize： 当fit_intercept设置为False时，该参数将被忽略。 如果为真，则回归前的回归系数X将通过减去平均值并除以l2-范数而归一化。\n",
    "#copy_X：是否对X数组进行复制,默认为True\n",
    "#n_jobs：指定线程数\n",
    "linear = sk_linear.LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=1)\n",
    "linear.fit(x_train, y_train)\n",
    "acc = linear.score(x_test, y_test) # get the coefficient of determination R^2\n",
    "print(\"Linear Regression:\")\n",
    "print(\"截距:\"), linear.intercept_\n",
    "print(\"系数:\"), linear.coef_\n",
    "print(\"线性回归模型评价:\"), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: 0.8\n"
     ]
    }
   ],
   "source": [
    "## Logistic Regression\n",
    "import sklearn.linear_model as sk_linear\n",
    "## 参数说明：\n",
    "#penalty：使用指定正则化项（默认：l2）\n",
    "#dual: n_samples > n_features取False（默认）\n",
    "#C：正则化强度的反，值越小正则化强度越大\n",
    "#n_jobs: 指定线程数\n",
    "#random_state：随机数生成器\n",
    "#fit_intercept: 是否需要常量\n",
    "logistic = sk_linear.LogisticRegression(penalty='l2', dual=False, C=1.0, n_jobs=1, random_state=20, fit_intercept=True)\n",
    "logistic.fit(x_train, y_train)\n",
    "acc = logistic.score(x_test, y_test)\n",
    "print(\"Evaluation:\"), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian朴素贝叶斯模型评价: 0.9238095238095239\n"
     ]
    }
   ],
   "source": [
    "## Naive Bayes\n",
    "import sklearn.naive_bayes as sk_bayes\n",
    "##参数说明：\n",
    "#alpha：平滑参数\n",
    "#fit_prior：是否要学习类的先验概率；false-使用统一的先验概率\n",
    "#class_prior: 是否指定类的先验概率；若指定则不能根据参数调整\n",
    "#binarize: 二值化的阈值，若为None，则假设输入由二进制向量组成\n",
    "naive_bayes1 = sk_bayes.MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None) # 多项式分布的朴素贝叶斯\n",
    "naive_bayes2 = sk_bayes.BernoulliNB(alpha=1.0, binarize=0.0, fit_prior=True, class_prior=None) # 伯努利分布的朴素贝叶斯\n",
    "naive_bayes3 = sk_bayes.GaussianNB() # Gaussian分布的贝叶斯\n",
    "naive_bayes3.fit(x_train, y_train)\n",
    "acc = naive_bayes3.score(x_test, y_test)  # return the mean of accuracy\n",
    "print(\"Gaussian朴素贝叶斯模型评价:\"), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desision Tree evaluation: 0.9428571428571428\n"
     ]
    }
   ],
   "source": [
    "## Desision Trees\n",
    "import sklearn.tree as sk_tree\n",
    "## 参数说明：\n",
    "#criterion ：特征选择准则gini/entropy\n",
    "#max_depth：树的最大深度，None-尽量下分\n",
    "#min_samples_split：分裂内部节点，所需要的最小样本树\n",
    "#min_samples_leaf：叶子节点所需要的最小样本数\n",
    "#max_features: 寻找最优分割点时的最大特征数\n",
    "#max_leaf_nodes：优先增长到最大叶子节点数\n",
    "#min_impurity_decrease：如果这种分离导致杂质的减少大于或等于这个值，则节点将被拆分。\n",
    "desision_tree = sk_tree.DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_split=2, min_samples_leaf=1, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0)\n",
    "desision_tree.fit(x_train, y_train)\n",
    "acc = desision_tree.score(x_test, y_test)  # 根据给定数据与标签返回正确率的均值 \n",
    "print(\"Desision Tree evaluation:\"), acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM evaluation: 0.9619047619047619\n"
     ]
    }
   ],
   "source": [
    "## SVM 支持向量机\n",
    "import sklearn.svm as sk_svm\n",
    "## 参数说明：\n",
    "#C：误差项的惩罚参数C\n",
    "#kernel：核函数选择 默认：rbf(高斯核函数)，可选：‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’\n",
    "#gamma: 核相关系数。浮点数，If gamma is ‘auto’ then 1/n_features will be used instead.点将被拆分。\n",
    "svm = sk_svm.SVC(C=1.0, kernel='rbf', gamma='auto')\n",
    "svm.fit(x_train, y_train)\n",
    "acc = svm.score(x_test, y_test)\n",
    "print(\"SVM evaluation:\"), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN evaluation: 0.9619047619047619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "## CNN 神经网络\n",
    "import sklearn.neural_network as sk_nn\n",
    "## 参数说明：\n",
    "#hidden_layer_sizes: 元祖\n",
    "#activation：激活函数 {‘identity’, ‘logistic’, ‘tanh’, ‘relu’}, 默认 ‘relu’\n",
    "#solver ：优化算法{‘lbfgs’, ‘sgd’, ‘Adam’}\n",
    "#alpha：L2惩罚(正则化项)参数\n",
    "#learning_rate：学习率 {‘constant’, ‘invscaling’, ‘adaptive’}\n",
    "#learning_rate_init：初始学习率，默认0.001\n",
    "#max_iter：最大迭代次数 默认200\n",
    "nn = sk_nn.MLPClassifier(activation='tanh', solver='adam', alpha=0.0001, learning_rate='adaptive', learning_rate_init=0.001, max_iter=200)\n",
    "nn.fit(x_train, y_train)\n",
    "acc = nn.score(x_test, y_test)\n",
    "print(\"NN evaluation:\"), acc\n",
    "\n",
    "## 特别：\n",
    "## 学习率中参数：\n",
    "#   constant: 有‘learning_rate_init’给定的恒定学习率\n",
    "#   incscaling：随着时间t使用’power_t’的逆标度指数不断降低学习率\n",
    "#   adaptive：只要训练损耗在下降，就保持学习率为’learning_rate_init’不变\n",
    "## 优化算法参数：\n",
    "#   lbfgs：quasi-Newton方法的优化器\n",
    "#   sgd：随机梯度下降\n",
    "#   adam： Kingma, Diederik, and Jimmy Ba提出的机遇随机梯度的优化器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The evaluation of KNN model (classification): 0.9428571428571428\n",
      "KNN model(regression) evaluation: 0.926060606060606\n"
     ]
    }
   ],
   "source": [
    "## KNN K-近邻算法 as classifier or regressor\n",
    "import sklearn.neighbors as sk_neighbors\n",
    "## 参数说明：\n",
    "#n_neighbors： 使用邻居的数目\n",
    "#n_jobs：并行任务数\n",
    "## KNN classifier\n",
    "neighbors_classifier = sk_neighbors.KNeighborsClassifier(n_neighbors=5, n_jobs=1)\n",
    "neighbors_classifier.fit(x_train, y_train)\n",
    "acc = neighbors_classifier.score(x_test, y_test)  # retrun the mean of accuracy\n",
    "print(\"The evaluation of KNN model (classification):\"), acc\n",
    "\n",
    "## KNN regressor\n",
    "neighbors_regressor = sk_neighbors.KNeighborsRegressor(n_neighbors=5, n_jobs=1)\n",
    "neighbors_regressor.fit(x_train, y_train)\n",
    "acc = neighbors_regressor.score(x_test, y_test)  # return the coefficient of determination R^2\n",
    "print(\"KNN model(regression) evaluation:\"), acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cross-Validation:', array([1.        , 0.93333333, 1.        , 1.        , 0.86666667,\n",
      "       0.93333333, 0.93333333, 1.        , 1.        , 1.        ]))\n"
     ]
    }
   ],
   "source": [
    "## 交叉验证cross-validation: evaluating estimator performance\n",
    "import sklearn.neighbors as sk_neighbors\n",
    "neighbors = sk_neighbors.KNeighborsClassifier(n_neighbors=5, n_jobs=1)\n",
    "import sklearn.model_selection as sk_model_selection\n",
    "## 参数说明：\n",
    "#model：拟合数据的模型\n",
    "#cv ： 子集个数 就是k\n",
    "#scoring: 打分参数 默认‘accuracy’、可选‘f1’、‘precision’、‘recall’ 、‘roc_auc’、'neg_log_loss'\n",
    "accs = sk_model_selection.cross_val_score(neighbors, iris_x, y=iris_y, scoring='accuracy', cv=10, n_jobs=1)\n",
    "print(\"Cross-Validation:\", accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save and load the model 模型的保存和载入\n",
    "import sklearn.externals as sk_externals\n",
    "# save the modle to a file named 'neighbors.pkl'\n",
    "sk_externals.joblib.dump(neighbors, 'neighbors.pkl')\n",
    "neighbors_load = sk_externals.joblib.load('neighbors.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
